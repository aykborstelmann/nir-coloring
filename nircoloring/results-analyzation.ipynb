{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import torch\n",
    "from pytorch_fid.fid_score import compute_statistics_of_path, calculate_frechet_distance, \\\n",
    "    calculate_activation_statistics\n",
    "from pytorch_fid.inception import InceptionV3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from config import CYCLE_GAN_DIR_RESULTS, CALTECH_GRAY_DATASET_OUT, \\\n",
    "    CALTECH_NIR_DATASET_OUT\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayk/miniconda3/envs/nir-coloring/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ayk/miniconda3/envs/nir-coloring/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "num_avail_cpus = len(os.sched_getaffinity(0))\n",
    "num_workers = min(num_avail_cpus, 8)\n",
    "batch_size = 50\n",
    "\n",
    "device = torch.device('cuda' if (torch.cuda.is_available()) else 'cpu')\n",
    "\n",
    "dims = 2048\n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "model = InceptionV3([block_idx]).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def calculate_fid_for_file_list(result_files, ground_truth_stat):\n",
    "    m1, s1 = ground_truth_stat\n",
    "    m2, s2 = calculate_activation_statistics(sorted(result_files), model, batch_size=batch_size, device=device,\n",
    "                                             num_workers=num_workers)\n",
    "    return calculate_frechet_distance(m1, s1, m2, s2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "batch_size should be a positive integer value, but got batch_size=0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [37], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m     m1, s1 \u001B[38;5;241m=\u001B[39m compute_statistics_of_path(inception_values_files, model, dims\u001B[38;5;241m=\u001B[39mdims, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[1;32m      5\u001B[0m                                         num_workers\u001B[38;5;241m=\u001B[39mnum_workers)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m----> 7\u001B[0m     m1, s1 \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_statistics_of_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_b_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     np\u001B[38;5;241m.\u001B[39msavez(inception_values_files, mu\u001B[38;5;241m=\u001B[39mm1, sigma\u001B[38;5;241m=\u001B[39ms1)\n",
      "File \u001B[0;32m~/miniconda3/envs/nir-coloring/lib/python3.10/site-packages/pytorch_fid/fid_score.py:240\u001B[0m, in \u001B[0;36mcompute_statistics_of_path\u001B[0;34m(path, model, batch_size, dims, device, num_workers)\u001B[0m\n\u001B[1;32m    237\u001B[0m     path \u001B[38;5;241m=\u001B[39m pathlib\u001B[38;5;241m.\u001B[39mPath(path)\n\u001B[1;32m    238\u001B[0m     files \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m([file \u001B[38;5;28;01mfor\u001B[39;00m ext \u001B[38;5;129;01min\u001B[39;00m IMAGE_EXTENSIONS\n\u001B[1;32m    239\u001B[0m                    \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m path\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*.\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(ext))])\n\u001B[0;32m--> 240\u001B[0m     m, s \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_activation_statistics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m m, s\n",
      "File \u001B[0;32m~/miniconda3/envs/nir-coloring/lib/python3.10/site-packages/pytorch_fid/fid_score.py:225\u001B[0m, in \u001B[0;36mcalculate_activation_statistics\u001B[0;34m(files, model, batch_size, dims, device, num_workers)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_activation_statistics\u001B[39m(files, model, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, dims\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2048\u001B[39m,\n\u001B[1;32m    207\u001B[0m                                     device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;124;03m\"\"\"Calculation of the statistics used by the FID.\u001B[39;00m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;124;03m    Params:\u001B[39;00m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;124;03m    -- files       : List of image files paths\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;124;03m               the inception model.\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 225\u001B[0m     act \u001B[38;5;241m=\u001B[39m \u001B[43mget_activations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m     mu \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(act, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    227\u001B[0m     sigma \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcov(act, rowvar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/envs/nir-coloring/lib/python3.10/site-packages/pytorch_fid/fid_score.py:119\u001B[0m, in \u001B[0;36mget_activations\u001B[0;34m(files, model, batch_size, dims, device, num_workers)\u001B[0m\n\u001B[1;32m    116\u001B[0m     batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(files)\n\u001B[1;32m    118\u001B[0m dataset \u001B[38;5;241m=\u001B[39m ImagePathDataset(files, transforms\u001B[38;5;241m=\u001B[39mTF\u001B[38;5;241m.\u001B[39mToTensor())\n\u001B[0;32m--> 119\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mdrop_last\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    125\u001B[0m pred_arr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty((\u001B[38;5;28mlen\u001B[39m(files), dims))\n\u001B[1;32m    127\u001B[0m start_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/nir-coloring/lib/python3.10/site-packages/torch/utils/data/dataloader.py:350\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    346\u001B[0m             sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m batch_sampler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;66;03m# auto_collation without custom batch_sampler\u001B[39;00m\n\u001B[0;32m--> 350\u001B[0m     batch_sampler \u001B[38;5;241m=\u001B[39m \u001B[43mBatchSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43msampler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdrop_last\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size \u001B[38;5;241m=\u001B[39m batch_size\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop_last \u001B[38;5;241m=\u001B[39m drop_last\n",
      "File \u001B[0;32m~/miniconda3/envs/nir-coloring/lib/python3.10/site-packages/torch/utils/data/sampler.py:232\u001B[0m, in \u001B[0;36mBatchSampler.__init__\u001B[0;34m(self, sampler, batch_size, drop_last)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, sampler: Union[Sampler[\u001B[38;5;28mint\u001B[39m], Iterable[\u001B[38;5;28mint\u001B[39m]], batch_size: \u001B[38;5;28mint\u001B[39m, drop_last: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# Since collections.abc.Iterable does not check for `__getitem__`, which\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# is one way for an object to be an iterable, we don't do an `isinstance`\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# check here.\u001B[39;00m\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(batch_size, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(batch_size, \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \\\n\u001B[1;32m    231\u001B[0m             batch_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 232\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_size should be a positive integer value, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    233\u001B[0m                          \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got batch_size=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(batch_size))\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(drop_last, \u001B[38;5;28mbool\u001B[39m):\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdrop_last should be a boolean value, but got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    236\u001B[0m                          \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdrop_last=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(drop_last))\n",
      "\u001B[0;31mValueError\u001B[0m: batch_size should be a positive integer value, but got batch_size=0"
     ]
    }
   ],
   "source": [
    "test_b_dir = join(CALTECH_GRAY_DATASET_OUT, \"testA\")\n",
    "inception_values_files = join(test_b_dir, \"inception-values.npz\")\n",
    "if os.path.exists(inception_values_files):\n",
    "    m1, s1 = compute_statistics_of_path(inception_values_files, model, dims=dims, batch_size=batch_size, device=device,\n",
    "                                        num_workers=num_workers)\n",
    "else:\n",
    "    m1, s1 = compute_statistics_of_path(test_b_dir, model, dims=dims, batch_size=batch_size, device=device,\n",
    "                                        num_workers=num_workers)\n",
    "    np.savez(inception_values_files, mu=m1, sigma=s1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NETWORK_NAME_MAP = {\n",
    "    \"nir_cyclegan_unet_ralsgan_sampling\": \"Verbessertes Sampling\",\n",
    "    \"nir_cyclegan_unet_ralsgan_sampling_ssim\": \"SSIM\",\n",
    "    \"nir_cyclegan_unet_ralsgan_sampling_ssim_ttur\": \"TTUR\",\n",
    "    \"nir_cyclegan_unet_ralsgan_sampling_ssim_ttur_2_cyc\": \"Verbessertes Cycle Consistency\",\n",
    "    \"nir_cyclegan_unet_ralsgan_sampling_ssim_ttur_2_cyc_spectral_normalization\": \"Spectral Normalization\",\n",
    "    \"nir_cyclegan_unet_ralsgan_sampling_ssim_ttur_2_cyc_spectral_normalization_reduced_cycle\": \"Spectral Normalization (geringeres $\\lambda$)\",\n",
    "    \"cut\": \"CUT\",\n",
    "    \"gray_cut\": \"CUT (Grauwert)\",\n",
    "    \"nir_cyclegan_unet_ralsgan_sampling_ssim_ttur_2_cyc_spectral_normalization_reduced_cycle_detach\": \"Detach Fix\"\n",
    "}\n",
    "\n",
    "comparable_networks = [\n",
    "    \"CUT\",\n",
    "    \"CUT (Grauwert)\"\n",
    "]\n",
    "\n",
    "\n",
    "def map_epoch_name(name):\n",
    "    name = name.removeprefix(\"test_\")\n",
    "    if name == \"latest\":\n",
    "        return 200\n",
    "    return int(name)\n",
    "\n",
    "\n",
    "def map_network_name(name):\n",
    "    if name in NETWORK_NAME_MAP.keys():\n",
    "        return NETWORK_NAME_MAP[name]\n",
    "    return name\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for network_name in os.listdir(CYCLE_GAN_DIR_RESULTS):\n",
    "    if map_network_name(network_name) not in comparable_networks:\n",
    "        continue\n",
    "\n",
    "    network_dir = join(CYCLE_GAN_DIR_RESULTS, network_name)\n",
    "    for epoch_result in os.listdir(network_dir):\n",
    "        epoch_result_dir = pathlib.Path(join(network_dir, epoch_result, \"images\"))\n",
    "\n",
    "        if \"cut\" in network_name:\n",
    "            glob = epoch_result_dir.glob(\"fake_B/*.png\")\n",
    "        else:\n",
    "            glob = epoch_result_dir.glob(\"*_fake.png\")\n",
    "        fid = calculate_fid_for_file_list(glob, (m1, s1))\n",
    "        results.append([map_network_name(network_name), map_epoch_name(epoch_result), fid])\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"Network\", \"Epoch\", \"FID\"])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.groupby(by=[\"Network\", \"Epoch\"]).min()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"Network\", \"Epoch\"])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_per_network_fid = df[df[\"Network\"].isin(comparable_networks)].groupby(by=[\"Epoch\", \"Network\"]).min()\n",
    "epoch_per_network_fid = epoch_per_network_fid.sort_index()\n",
    "epoch_per_network_fid: pd.DataFrame = epoch_per_network_fid.reset_index()\n",
    "epoch_per_network_fid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_per_network_fid = epoch_per_network_fid.rename(columns={\"Network\": \"Netzwerk\", \"Epoch\": \"Epoche\"})\n",
    "plt.title(\"FID der Test Ergebnisse pro Epoche\")\n",
    "sns.barplot(x=\"Epoche\", y=\"FID\", hue=\"Netzwerk\", data=epoch_per_network_fid, hue_order=comparable_networks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.linspace(0, 200, num=400)\n",
    "y = np.minimum(-1 * x + 200, 100)\n",
    "\n",
    "ax: plt.Axes = sns.lineplot(x=x, y=y)\n",
    "ax.set_xlabel(\"Epochen\")\n",
    "ax.set_ylabel(\"$\\lambda$\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
